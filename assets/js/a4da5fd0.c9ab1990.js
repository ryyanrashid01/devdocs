"use strict";(self.webpackChunkdeploy_to_vm=self.webpackChunkdeploy_to_vm||[]).push([[3652],{8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>l});var s=t(6540);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}},9151:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"Resources/Setting up a ML Dev Env/test_setup","title":"Testing Your Setup","description":"Before diving into real-world machine learning projects, it\'s important to verify that your environment is correctly configured \u2014 especially GPU acceleration.","source":"@site/docs/Resources/Setting up a ML Dev Env/test_setup.md","sourceDirName":"Resources/Setting up a ML Dev Env","slug":"/Resources/Setting up a ML Dev Env/test_setup","permalink":"/devdocs/docs/Resources/Setting up a ML Dev Env/test_setup","draft":false,"unlisted":false,"editUrl":"https://github.com/ryyanrashid01/devdocs/edit/main/docs/Resources/Setting up a ML Dev Env/test_setup.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Docker Setup","permalink":"/devdocs/docs/Resources/Setting up a ML Dev Env/docker"}}');var r=t(4848),i=t(8453);const o={sidebar_position:7},l="Testing Your Setup",c={},d=[{value:"\ud83e\uddea PyTorch Test",id:"-pytorch-test",level:2},{value:"\ud83e\uddea TensorFlow Test",id:"-tensorflow-test",level:2},{value:"\ud83d\udcd3 Jupyter Notebook Test",id:"-jupyter-notebook-test",level:2},{value:"\ud83e\uddea Optional: Stress Test Your GPU",id:"-optional-stress-test-your-gpu",level:2},{value:"\ud83d\udd25 GPU Burn Test",id:"-gpu-burn-test",level:3},{value:"Notes",id:"notes",level:4},{value:"\ud83e\uddef Troubleshooting",id:"-troubleshooting",level:2}];function a(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"testing-your-setup",children:"Testing Your Setup"})}),"\n",(0,r.jsx)(n.p,{children:"Before diving into real-world machine learning projects, it's important to verify that your environment is correctly configured \u2014 especially GPU acceleration."}),"\n",(0,r.jsxs)(n.p,{children:["This page walks you through minimal tests using ",(0,r.jsx)(n.strong,{children:"PyTorch"}),", ",(0,r.jsx)(n.strong,{children:"TensorFlow"}),", and ",(0,r.jsx)(n.strong,{children:"Jupyter"})," to confirm everything is running smoothly."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-pytorch-test",children:"\ud83e\uddea PyTorch Test"}),"\n",(0,r.jsx)(n.p,{children:"Activate your conda environment if not already:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"conda activate ml-gpu\n"})}),"\n",(0,r.jsx)(n.p,{children:"Then run this Python script:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import torch\n\nprint("PyTorch version:", torch.__version__)\nprint("CUDA available:", torch.cuda.is_available())\n\nif torch.cuda.is_available():\n    print("GPU Name:", torch.cuda.get_device_name(0))\n'})}),"\n",(0,r.jsx)(n.p,{children:"Expected output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"PyTorch version: 2.x\nCUDA available: True\nGPU Name: NVIDIA GeForce RTX 4080\n"})}),"\n",(0,r.jsx)(n.admonition,{title:"GPU not found?",type:"tip",children:(0,r.jsxs)(n.p,{children:["Make sure you installed PyTorch with CUDA support from the ",(0,r.jsx)(n.a,{href:"https://pytorch.org/get-started/locally/",children:"official instructions"}),". Go to ",(0,r.jsx)(n.a,{href:"./CUDA",children:"CUDA Setup"})," for more details."]})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-tensorflow-test",children:"\ud83e\uddea TensorFlow Test"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import tensorflow as tf\n\nprint(\"TensorFlow version:\", tf.__version__)\nprint(tf.config.list_physical_devices('GPU'))\n"})}),"\n",(0,r.jsx)(n.p,{children:"Expected output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"TensorFlow version: 2.x\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"})}),"\n",(0,r.jsx)(n.p,{children:"If no GPUs show up, double-check:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"You installed the GPU-enabled TensorFlow"}),"\n",(0,r.jsx)(n.li,{children:"CUDA and cuDNN are properly set up"}),"\n",(0,r.jsxs)(n.li,{children:["Go to ",(0,r.jsx)(n.a,{href:"./CUDA",children:"CUDA Setup"})," for more details."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-jupyter-notebook-test",children:"\ud83d\udcd3 Jupyter Notebook Test"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Launch JupyterLab:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"jupyter lab\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsxs)(n.li,{children:["Create a new Python 3 notebook in your ",(0,r.jsx)(n.code,{children:"ml-gpu"})," environment."]}),"\n",(0,r.jsx)(n.li,{children:"Run either the PyTorch or TensorFlow test cells above."}),"\n"]}),"\n",(0,r.jsxs)(n.admonition,{title:"Where to place your notebooks?",type:"info",children:[(0,r.jsxs)(n.p,{children:["You can organize notebooks in a ",(0,r.jsx)(n.code,{children:"notebooks/"})," folder at the root of your repo:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"my-project/\n\u251c\u2500\u2500 env.yml\n\u251c\u2500\u2500 notebooks/\n\u2502   \u251c\u2500\u2500 test-pytorch.ipynb\n\u2502   \u2514\u2500\u2500 test-tensorflow.ipynb\n"})})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-optional-stress-test-your-gpu",children:"\ud83e\uddea Optional: Stress Test Your GPU"}),"\n",(0,r.jsx)(n.p,{children:"Want to see your GPU in action? Here's a fun little stress test script using PyTorch:"}),"\n",(0,r.jsx)(n.h3,{id:"-gpu-burn-test",children:"\ud83d\udd25 GPU Burn Test"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import torch\nimport time\n\ndef burn_gpu(seconds=20, size=15000):\n\n    print("\ud83d\udd25 Starting GPU stress test...")\n    print("Device:", torch.cuda.get_device_name(0))\n\n    print(f"Allocating matrices of size {size}x{size}...")\n    try:\n        a = torch.randn(size, size, device="cuda")\n        b = torch.randn(size, size, device="cuda")\n    except RuntimeError as e:\n        print("\\n\u274c Failed to allocate matrices. Try using a smaller size.")\n        print("Error:", e)\n        return\n\n    print("Allocated two large matrices on the GPU.")\n\n    start = time.time()\n    iterations = 0\n\n    while time.time() - start < seconds:\n        c = torch.matmul(a, b)\n        torch.cuda.synchronize()\n        iterations += 1\n\n    print(f"\\n\u2705 Done. Completed {iterations} matrix multiplications in {seconds} seconds.")\n\nif **name** == "**main**":\n\n    burn_gpu(seconds=20, size=15000)\n'})}),"\n",(0,r.jsx)(n.h4,{id:"notes",children:"Notes"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Adjust size carefully based on your GPU VRAM. For 4GB or lower, use size=8000 or less."}),"\n",(0,r.jsxs)(n.li,{children:["You can monitor usage using:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"nvidia-smi"})," (CLI)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"nvtop"})," (Linux CLI UI: ",(0,r.jsx)(n.code,{children:"sudo apt install nvtop; nvtop"}),")"]}),"\n",(0,r.jsx)(n.li,{children:"Task Manager > Performance > GPU (Windows)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://ik.imagekit.io/devdocs/img/ml_env/nvtop.png",alt:"nvtop"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-troubleshooting",children:"\ud83e\uddef Troubleshooting"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Issue"}),(0,r.jsx)(n.th,{children:"Fix"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"torch.cuda.is_available()"})," is False"]}),(0,r.jsx)(n.td,{children:"Check CUDA version and reinstall PyTorch with GPU support"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"nvidia-smi"})," not found"]}),(0,r.jsx)(n.td,{children:"NVIDIA driver missing or not loaded"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"TensorFlow sees no GPU"}),(0,r.jsxs)(n.td,{children:["Double-check cuDNN + TensorFlow versions and verify with ",(0,r.jsx)(n.code,{children:"pip list"})]})]})]})]}),"\n",(0,r.jsx)(n.hr,{})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(a,{...e})}):a(e)}}}]);